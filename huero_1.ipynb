{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"huero_1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_3VrIrdD3HKi","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","import argparse\n","import re\n","from keras.models import load_model\n","import nltk\n","from nltk.corpus import stopwords\n","import string\n","import json\n","from time import time\n","import pickle\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n","from keras.preprocessing import image\n","from keras.models import Model, load_model, Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split \n","from keras.utils import to_categorical\n","from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Activation\n","from keras.layers.merge import add\n","from keras.layers import Bidirectional\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, LambdaCallback\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKa1wrYHtTSR","colab_type":"code","outputId":"30e4b143-2b8a-4847-c4d8-678748adc470","executionInfo":{"status":"ok","timestamp":1565810219600,"user_tz":-330,"elapsed":1927,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B7MXjC7Qw44L","colab_type":"code","colab":{}},"source":["glove = open('/content/drive/My Drive/Datasets/glove.6B.50d.txt',encoding='utf-8')\n","d=open('/content/drive/My Drive/Datasets/data.txt').read()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYwshi05HO2B","colab_type":"code","colab":{}},"source":["#from google.colab import files\n","#files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l44KOL5K3bZt","colab_type":"code","outputId":"4ab10d46-ff86-42ac-bb57-2382bf98c466","executionInfo":{"status":"ok","timestamp":1565810219604,"user_tz":-330,"elapsed":1915,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#d=open('data.txt','r').read()\n","len(d)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3196213"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"Cryollsh3poY","colab_type":"code","colab":{}},"source":["d=d.lower().replace('\\n',' \\n ')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0AFMGMi4E6W","colab_type":"code","outputId":"167f800d-41f9-4e9a-88a1-b9992c5c2b19","executionInfo":{"status":"ok","timestamp":1565810219605,"user_tz":-330,"elapsed":1904,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["d[:100]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"well, prince, so genoa and lucca are now just family estates of the \\n buonapartes. but i warn you, '"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"QrviF05orBhS","colab_type":"code","colab":{}},"source":["text_in_words = [w for w in d.split(' ') if w.strip() != '' or w == '\\n']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BmtJNQirHP3","colab_type":"code","outputId":"407482a5-3f1d-485e-f7fe-9cc1f486b84b","executionInfo":{"status":"ok","timestamp":1565810219607,"user_tz":-330,"elapsed":1890,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(text_in_words)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["623708"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"7wDypTKtrNGK","colab_type":"code","outputId":"3d662cfb-d223-4e56-8af5-a400ad3772f9","executionInfo":{"status":"ok","timestamp":1565810219607,"user_tz":-330,"elapsed":1880,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["text_in_words[:100]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['\"well,',\n"," 'prince,',\n"," 'so',\n"," 'genoa',\n"," 'and',\n"," 'lucca',\n"," 'are',\n"," 'now',\n"," 'just',\n"," 'family',\n"," 'estates',\n"," 'of',\n"," 'the',\n"," '\\n',\n"," 'buonapartes.',\n"," 'but',\n"," 'i',\n"," 'warn',\n"," 'you,',\n"," 'if',\n"," 'you',\n"," \"don't\",\n"," 'tell',\n"," 'me',\n"," 'that',\n"," 'this',\n"," 'means',\n"," 'war,',\n"," '\\n',\n"," 'if',\n"," 'you',\n"," 'still',\n"," 'try',\n"," 'to',\n"," 'defend',\n"," 'the',\n"," 'infamies',\n"," 'and',\n"," 'horrors',\n"," 'perpetrated',\n"," 'by',\n"," 'that',\n"," '\\n',\n"," 'antichrist--i',\n"," 'really',\n"," 'believe',\n"," 'he',\n"," 'is',\n"," 'antichrist--i',\n"," 'will',\n"," 'have',\n"," 'nothing',\n"," 'more',\n"," '\\n',\n"," 'to',\n"," 'do',\n"," 'with',\n"," 'you',\n"," 'and',\n"," 'you',\n"," 'are',\n"," 'no',\n"," 'longer',\n"," 'my',\n"," 'friend,',\n"," 'no',\n"," 'longer',\n"," 'my',\n"," \"'faithful\",\n"," '\\n',\n"," \"slave,'\",\n"," 'as',\n"," 'you',\n"," 'call',\n"," 'yourself!',\n"," 'but',\n"," 'how',\n"," 'do',\n"," 'you',\n"," 'do?',\n"," 'i',\n"," 'see',\n"," 'i',\n"," 'have',\n"," 'frightened',\n"," '\\n',\n"," 'you--sit',\n"," 'down',\n"," 'and',\n"," 'tell',\n"," 'me',\n"," 'all',\n"," 'the',\n"," 'news.\"',\n"," '\\n',\n"," '\\n',\n"," 'it',\n"," 'was',\n"," 'in',\n"," 'july,']"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"Uk-fwYZYsGt-","colab_type":"code","outputId":"41160e3d-5237-4316-d1e2-ec71f53d2ece","executionInfo":{"status":"ok","timestamp":1565810220282,"user_tz":-330,"elapsed":2546,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Calculate word frequency\n","MIN_WORD_FREQUENCY=2\n","word_freq = {}\n","for word in text_in_words:\n","    word_freq[word] = word_freq.get(word, 0) + 1\n","\n","ignored_words = set()\n","for k, v in word_freq.items():\n","    if word_freq[k] < MIN_WORD_FREQUENCY:\n","        ignored_words.add(k)\n","\n","words = set(text_in_words)\n","print('Unique words before ignoring:', len(words))\n","print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n","words = sorted(set(words) - ignored_words)\n","print('Unique words after ignoring:', len(words))\n","\n","word_indices = dict((c, i) for i, c in enumerate(words))\n","indices_word = dict((i, c) for i, c in enumerate(words))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Unique words before ignoring: 39830\n","Ignoring words with frequency < 2\n","Unique words after ignoring: 18747\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vOKIBw4psdYI","colab_type":"code","outputId":"00c98e8a-4557-4fa0-cb3e-cfcc459ef973","executionInfo":{"status":"ok","timestamp":1565810220284,"user_tz":-330,"elapsed":2538,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(word_freq.keys())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["39830"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"3uZq2f5fWneI","colab_type":"code","outputId":"63263908-6867-42a8-ba07-347257942b75","executionInfo":{"status":"ok","timestamp":1565810220286,"user_tz":-330,"elapsed":2532,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["words[:100]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['\\n',\n"," '\"\\'i',\n"," '\"800',\n"," '\"a',\n"," '\"a-tu!\"',\n"," '\"about',\n"," '\"adieu,',\n"," '\"afraid',\n"," '\"after',\n"," '\"ah',\n"," '\"ah!',\n"," '\"ah!\"',\n"," '\"ah,',\n"," '\"all',\n"," '\"allow',\n"," '\"always',\n"," '\"am',\n"," '\"an',\n"," '\"and',\n"," '\"andrew',\n"," '\"andrew,',\n"," '\"anna',\n"," '\"another',\n"," '\"any',\n"," '\"are',\n"," '\"aren\\'t',\n"," '\"arrange',\n"," '\"as',\n"," '\"ask',\n"," '\"at',\n"," '\"bad!',\n"," '\"be',\n"," '\"because',\n"," '\"because,',\n"," '\"before',\n"," '\"believe',\n"," '\"besides',\n"," '\"besides,',\n"," '\"besides,\"',\n"," '\"better',\n"," '\"bind',\n"," '\"board',\n"," '\"bolkonski!\"',\n"," '\"bonaparte',\n"," '\"bonjour,',\n"," '\"boris',\n"," '\"both',\n"," '\"brigand!',\n"," '\"bring',\n"," '\"brothers!',\n"," '\"brothers!\"',\n"," '\"buonaparte',\n"," '\"buonaparte?\"',\n"," '\"but',\n"," '\"but,',\n"," '\"but...',\n"," '\"bwing',\n"," '\"by',\n"," '\"c\\'est',\n"," '\"call',\n"," '\"calm',\n"," '\"can',\n"," '\"captain',\n"," '\"captain,',\n"," '\"catch',\n"," '\"cette',\n"," '\"charming!\"',\n"," '\"christ',\n"," '\"clear',\n"," '\"colonel,\"',\n"," '\"come',\n"," '\"come!',\n"," '\"come,',\n"," '\"commander',\n"," '\"confound',\n"," '\"count',\n"," '\"count!',\n"," '\"count,',\n"," '\"countess',\n"," '\"countess,',\n"," '\"cut',\n"," '\"darling',\n"," '\"dear',\n"," '\"dear,',\n"," '\"dear-est!\"',\n"," '\"delighted',\n"," '\"denisov,',\n"," '\"der',\n"," '\"devil',\n"," '\"did',\n"," '\"didn\\'t',\n"," '\"dieu',\n"," '\"dispositions',\n"," '\"do',\n"," '\"does',\n"," '\"don\\'t',\n"," '\"don\\'t!',\n"," '\"don\\'t,',\n"," '\"done',\n"," '\"dronushka,']"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"-UfPHUegweXB","colab_type":"text"},"source":["If we remember, at this point we have text_in_words which is an array containing all the corpus word-by-word. We need to create sequences of size SEQUENCE_LEN (another parameter that can be picked by hand) and store them in sentences, and in the same index, store the next word in next_words."]},{"cell_type":"code","metadata":{"id":"dWS_uRIx4X0Z","colab_type":"code","outputId":"7e022d92-1459-40e4-9855-d41cf0cab067","executionInfo":{"status":"ok","timestamp":1565810223763,"user_tz":-330,"elapsed":6000,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# cut the text in semi-redundant sequences of SEQUENCE_LEN words\n","STEP = 1\n","SEQUENCE_LEN=100\n","sentences = []\n","next_words = []\n","ignored = 0\n","for i in range(0, len(text_in_words) - SEQUENCE_LEN, STEP):\n","    # Only add sequences where no word is in ignored_words\n","    if len(set(text_in_words[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n","        sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n","        next_words.append(text_in_words[i + SEQUENCE_LEN])\n","    else:\n","        ignored = ignored+1\n","print('Ignored sequences:', ignored)\n","print('Remaining sequences:', len(sentences))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Ignored sequences: 585009\n","Remaining sequences: 38599\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NjKkyp2u_bFH","colab_type":"code","colab":{}},"source":["sentences, sentences_test, next_words, next_words_test = train_test_split(sentences, next_words,shuffle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kF4outiyEiaK","colab_type":"code","outputId":"a720f449-3a43-47d5-f6ee-f4a80305eeac","executionInfo":{"status":"ok","timestamp":1565810223772,"user_tz":-330,"elapsed":5995,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(sentences_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9650"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"qILEVMR6y5Ah","colab_type":"code","colab":{}},"source":["model = Sequential()\n","dropout=3\n","model.add(Bidirectional(LSTM(128), input_shape=(SEQUENCE_LEN, len(words))))\n","if dropout > 0:\n","    model.add(Dropout(dropout))\n","model.add(Dense(len(words)))\n","model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WrtTFiMC1lC","colab_type":"code","colab":{}},"source":["model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmj7qjUAC64D","colab_type":"code","outputId":"c8f81eea-d754-4137-d6b3-1dfe8c066068","executionInfo":{"status":"ok","timestamp":1565810224585,"user_tz":-330,"elapsed":6773,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_2 (Bidirection (None, 256)               19329024  \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 18747)             4817979   \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 18747)             0         \n","=================================================================\n","Total params: 24,147,003\n","Trainable params: 24,147,003\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Gr1uZzo2o7R","colab_type":"text"},"source":["Without word filtering, I had roughly 1 million sentences (len(sentences) = 1000000), SEQUENCE_LEN = 10 and 40,000 different words (len(words)=40000). With these numbers, x had a size of 400,000,000,000(!). Considering that in numpy is 1 byte, this gave me an approximate of 400 GB of memory(!).\n","Hence the need of data generators. Using data generators, you feed the model with chunks of the training set, one for each step, instead of feeding everything at once."]},{"cell_type":"code","metadata":{"id":"bp29T4Vj2rC8","colab_type":"code","colab":{}},"source":["def generator(sentence_list, next_word_list, batch_size):\n","    index = 0\n","    while True:\n","        x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n","        y = np.zeros((batch_size, len(words)), dtype=np.bool)\n","        for i in range(batch_size):\n","            for t, w in enumerate(sentence_list[index]):\n","                x[i, t, word_indices[w]] = 1\n","            y[i, word_indices[next_word_list[index]]] = 1\n","\n","            index = index + 1\n","            if index == len(sentence_list):\n","                index = 0\n","        yield x, y\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdVWoZyR4He_","colab_type":"code","colab":{}},"source":["file_path = \"LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}.ckpt\" % (\n","    len(words),\n","    SEQUENCE_LEN,\n","    MIN_WORD_FREQUENCY\n",")\n","checkpoint_dir=os.path.dirname(file_path)\n","checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n","print_callback = LambdaCallback()\n","early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n","callbacks_list = [checkpoint, print_callback, early_stopping]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDo8Jqir4oMp","colab_type":"code","outputId":"4f89dfd2-8163-418d-fd19-c74ae5555c24","executionInfo":{"status":"error","timestamp":1565810233209,"user_tz":-330,"elapsed":15382,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["'''BATCH_SIZE=200\n","model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n","    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n","    epochs=20,\n","    callbacks=callbacks_list,\n","    validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),              \n","    validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)'''"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","  1/145 [..............................] - ETA: 12:22 - loss: 5.7816e-04 - acc: 0.9999"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-feb438756ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_words_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"a9MoDy-65yNw","colab_type":"code","outputId":"afa56ff9-5027-4626-f973-926a2c44a597","executionInfo":{"status":"ok","timestamp":1565810245023,"user_tz":-330,"elapsed":4750,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!ls {checkpoint_dir}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive\n","LSTM_LYRICS-epoch001\n","LSTM_LYRICS-epoch001.ckpt\n","LSTM_LYRICS-epoch001-words18747-sequence100-minfreq2-loss0.0006-acc0.9999-val_loss0.0005-val_acc0.9999.ckpt\n","LSTM_LYRICS-epoch001-words18747-sequence100-minfreq2-loss0.0006-acc0.9999-val_loss0.0006-val_acc0.9999.ckpt\n","LSTM_LYRICS-epoch001-words4758-sequence100-minfreq10-loss0.0020-acc0.9998-val_loss0.0020-val_acc0.9998.ckpt\n","sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A7KvD2ZHkMS4","colab_type":"code","colab":{}},"source":["model=load_model('LSTM_LYRICS-epoch001-words18747-sequence100-minfreq2-loss0.0006-acc0.9999-val_loss0.0005-val_acc0.9999.ckpt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"trEPiihqRSH1","colab_type":"code","colab":{}},"source":["\n","\"\"\"\n","Script to generate text from an already trained network (with lstm_train.py)\n","--By word--\n","It is necessary to at least provide the trained model and the vocabulary file\n","(generated also by lstm_train.py).\n","\"\"\"\n","\n","\n","\n","\n","def validate_seed(words, seed):\n","    \"\"\"Validate that all the words in the seed are part of the vocabulary\"\"\"\n","    print(\"\\nValidating that all the words in the seed are part of the vocabulary: \")\n","    seed_words = seed.split(\" \")\n","    valid = True\n","    for w in seed_words:\n","        print(w, end=\"\")\n","        if w in vocabulary:\n","            print(\" ✓ in vocabulary\")\n","        else:\n","            print(\" ✗ NOT in vocabulary\")\n","            valid = False\n","    return valid\n","\n","\n","# Functions from keras-team/keras/blob/master/examples/lstm_text_generation.py\n","def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","\n","def generate_text(model, indices_word, word_indices, seed,\n","                  sequence_length, quantity):\n","    \"\"\"\n","    Similar to lstm_train::on_epoch_end\n","    Used to generate text using a trained model\n","    :param model: the trained Keras model (with model.load)\n","    :param indices_word: a dictionary pointing to the words\n","    :param seed: a string to be used as seed (already validated and padded)\n","    :param sequence_length: how many words are given to the model to generate\n","    :param diversity: is the \"temperature\" of the sample function (usually between 0.1 and 2)\n","    :param quantity: quantity of words to generate\n","    :return: Nothing, for now only writes the text to console\n","    \"\"\"\n","    #sentence = seed.split(\" \")\n","    #print(\"----- Generating text\")\n","    #print('----- Diversity:' + str(diversity))\n","    #print('----- Generating with seed:\\n\"' + seed)\n","\n","    sentence=seed.split(\" \")\n","    for i in range(quantity):\n","        x_pred = np.zeros((1, sequence_length, len(words)))\n","        for t, word in enumerate(sentence):\n","            x_pred[0, t, word_indices[word]] = 1.\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds)\n","        next_word = indices_word[next_index]\n","\n","        sentence = sentence[1:]\n","        sentence.append(next_word)\n","\n","        print(\" \"+next_word, end=\"\")\n","    print(\"\\n\")\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-EJy-4An6lt","colab_type":"code","colab":{}},"source":["def seed_generator(sentence,batch_size):\n","        wo=[]\n","        batch_size=1\n","        wo=sentence.split()\n","        x = np.zeros((batch_size, SEQUENCE_LEN, len(words)), dtype=np.bool)\n","        #y = np.zeros((batch_size, len(words)), dtype=np.bool)\n","        for i in range(batch_size):\n","            for t, w in enumerate(wo):\n","                x[i, t, word_indices[w]] = 1\n","            #y[i, word_indices[next_word_list[index]]] = 1\n","\n","            #index = index + 1\n","            #if index == len(sentence_list):\n","            #    index = 0\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2D382QhobLO","colab_type":"code","colab":{}},"source":["texttt='a demonstrating reveal found, happen?'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHYNMbbuRUqe","colab_type":"code","outputId":"c5d17bbe-3c64-492d-c250-e6072aa79694","executionInfo":{"status":"ok","timestamp":1565814504786,"user_tz":-330,"elapsed":16074,"user":{"displayName":"Chirag Gandhi","photoUrl":"https://lh6.googleusercontent.com/-EHqA2yMr-Og/AAAAAAAAAAI/AAAAAAAAFJ0/zH20Mm_9wRs/s64/photo.jpg","userId":"09401843859168304307"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["generate_text(model,indices_word,word_indices,texttt,100,100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" impossibility various either. purse and quit \n"," happened?\" \n"," divided bosom dark think! taken gust knowledge disappeared. solemn, eyebrows, hospital. the giving tastes upset. cases attention. victory pulse, rewards weeping disordered endeavors abandoning preserves cloudlets poetic. progress fox. course! \n"," room: move, disagreed gentry blue blame horror krasnoe, battle.\" scowling, \n"," health, \n"," kutuzov,\" questioning (in chairs increased. deceived, millions, people's books, sternly character. conservatory. coming! continued, pond united, \n"," dorogobuzh evince short \n"," merrily. united, violence. utterance however,\" undressing, become curls piteous, malevolently. plumes continue. clapping style, bilibin,\" cold \n"," grade, concluded destination. suspicion. frankly scratching \n"," trick enormously\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDKgpYCzWa3v","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}